{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenoSpark for Singapore population genotypic frequency\n",
    "\n",
    "## First, generate the output files with the command syntax below:\n",
    "```\n",
    "$ vcftools --gzvcf chr[#].consolidate.eff.PPH.vcf.gz --freq --chr [#] --out chr[#]_analysis\n",
    "$ bcftools query -f '%CHROM\\t%POS\\t%ID\\n' chr[#].consolidate.eff.PPH.vcf.gz -o chr[#]_rsID\n",
    "```\n",
    "\n",
    "#### * You may try freqGenerator.sh to generate the above files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "__author__ = 'mdc_hk'\n",
    "version = '1.0'\n",
    "\n",
    "# Description: To build the database on the pyspark DataFrame\n",
    "# Usage: -\n",
    "# Example: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime, multiprocessing, os, re, shutil, sys, subprocess, time, logging\n",
    "\n",
    "import pyspark.sql.types as typ\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "# Specify schemas\n",
    "\n",
    "schema_Freq = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_ALLELES\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_CHR\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_1\", typ.StringType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_2\", typ.StringType(), False),\n",
    "])\n",
    "\n",
    "schema_rsID = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ID\", typ.StringType(), True),\n",
    "])\n",
    "\n",
    "schema_Freq_DF = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_ALLELES\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_CHR\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_1\", typ.StringType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_2\", typ.StringType(), False),\n",
    "    typ.StructField(\"ID\", typ.StringType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chr10'], ['chr11'], ['chr12'], ['chr13'], ['chr14'], ['chr15'], ['chr16'], ['chr17'], ['chr18'], ['chr19'], ['chr1'], ['chr20'], ['chr21'], ['chr22'], ['chr2'], ['chr3'], ['chr4'], ['chr5'], ['chr6'], ['chr7'], ['chr8'], ['chr9']]\n"
     ]
    }
   ],
   "source": [
    "# Setting up File Paths and Lists\n",
    "\n",
    "from hdfs import Config\n",
    "client = Config().get_client('dev')\n",
    "\n",
    "workingFolder_Indian = \"SgIndian_vcf/dataFreeze_Feb2013/SNP/biAllele/\"\n",
    "\n",
    "workingFolder_Malay = \"SgMalay_vcf/2012_05/snps/\"\n",
    "\n",
    "# Filing number of unique samples found in the working folder...\n",
    "\n",
    "freqFiles_Indian = [f for f in client.list(workingFolder_Indian) if re.match(r'chr\\d+_analysis\\.frq', f)]\n",
    "rsIDFiles_Indian = [f for f in client.list(workingFolder_Indian) if re.match(r'chr\\d+_rsID', f)]\n",
    "freqFiles_Malay = [f for f in client.list(workingFolder_Malay) if re.match(r'chr\\d+_analysis\\.frq', f)]\n",
    "rsIDFiles_Malay = [f for f in client.list(workingFolder_Malay) if re.match(r'chr\\d+_rsID', f)]\n",
    "\n",
    "freqFilesID_pre = re.compile(r'(chr\\d+)_analysis\\.frq')\n",
    "freqFilesID = []\n",
    "for file in freqFiles_Indian:\n",
    "    freqFilesID.append(freqFilesID_pre.findall(file))\n",
    "\n",
    "print(freqFilesID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain dataset\n",
    "\n",
    "# suffixFreqID = ['_analysis.frq', '_rsID']\n",
    "freqDF_Indian = spark.createDataFrame([], schema_Freq_DF)\n",
    "freqDF_Malay = spark.createDataFrame([], schema_Freq_DF)\n",
    "\n",
    "for ID in freqFilesID:\n",
    "    df1 = spark.read.csv(workingFolder_Indian + ID[0] + \"_analysis.frq\", header=True, schema=schema_Freq, sep='\\t').alias('df1')\n",
    "    df2 = spark.read.csv(workingFolder_Indian + ID[0] + \"_rsID\", header=False, schema=schema_rsID, sep='\\t').alias('df2')\n",
    "    freqChrN_working = df2.join(df1, df2.POS == df1.POS).select('df1.*','df2.ID')\n",
    "    freqDF_Indian = freqDF_Indian.union(freqChrN_working)\n",
    "    \n",
    "for ID in freqFilesID:\n",
    "    df1 = spark.read.csv(workingFolder_Malay + ID[0] + \"_analysis.frq\", header=True, schema=schema_Freq, sep='\\t').alias('df1')\n",
    "    df2 = spark.read.csv(workingFolder_Malay + ID[0] + \"_rsID\", header=False, schema=schema_rsID, sep='\\t').alias('df2')\n",
    "    freqChrN_working = df2.join(df1, df2.POS == df1.POS).select('df1.*','df2.ID')\n",
    "    freqDF_Malay = freqDF_Malay.union(freqChrN_working)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqDF_Indian_working = freqDF_Indian.withColumn(\"ETHNIC\", lit(\"Indian\"))\n",
    "freqDF_Malay_working = freqDF_Malay.withColumn(\"ETHNIC\", lit(\"Malay\"))\n",
    "freqDF_working = freqDF_Malay_working.union(freqDF_Indian_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+-----+-------------+-------------+----------+------+\n",
      "|CHROM|   POS|N_ALLELES|N_CHR|ALLELE_FREQ_1|ALLELE_FREQ_2|        ID|ETHNIC|\n",
      "+-----+------+---------+-----+-------------+-------------+----------+------+\n",
      "|   10| 94426|        2|   72|   C:0.680556|   T:0.319444|rs10904045|Indian|\n",
      "|   10|119679|        2|   72|   G:0.986111|  T:0.0138889|         .|Indian|\n",
      "|   10|121816|        2|   72|   T:0.708333|   C:0.291667| rs7099775|Indian|\n",
      "|   10|122217|        2|   72|   G:0.930556|  T:0.0694444|rs35942159|Indian|\n",
      "|   10|124381|        2|   72|   A:0.680556|   G:0.319444| rs7087771|Indian|\n",
      "|   10|124490|        2|   72|   C:0.986111|  T:0.0138889|         .|Indian|\n",
      "|   10|124703|        2|   72|   C:0.930556|  T:0.0694444|rs12782029|Indian|\n",
      "|   10|124729|        2|   72|   A:0.930556|  C:0.0694444| rs9419540|Indian|\n",
      "|   10|125008|        2|   72|   G:0.333333|   C:0.666667|rs10795293|Indian|\n",
      "|   10|125009|        2|   72|   G:0.333333|   A:0.666667|rs10795294|Indian|\n",
      "+-----+------+---------+-----+-------------+-------------+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freqDF_working.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+-------------+-------------+\n",
      "|ETHNIC|       ID|CHROM|ALLELE_FREQ_1|ALLELE_FREQ_2|\n",
      "+------+---------+-----+-------------+-------------+\n",
      "|Indian|rs4109479|   11|  C:0.0434783|   T:0.956522|\n",
      "+------+---------+-----+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freqDF_working.select(\"ETHNIC\", \"ID\", \"CHROM\", \"ALLELE_FREQ_1\", \"ALLELE_FREQ_2\").filter(\"ID == 'rs4109479'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"select * from freqDF_working\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 9922922\n",
      "root\n",
      " |-- CHROM: integer (nullable = true)\n",
      " |-- POS: integer (nullable = true)\n",
      " |-- N_ALLELES: integer (nullable = true)\n",
      " |-- N_CHR: integer (nullable = true)\n",
      " |-- ALLELE_FREQ_1: string (nullable = true)\n",
      " |-- ALLELE_FREQ_2: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- ETHNIC: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "freqDF_working.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+\n",
      "|       ID|ALLELE_FREQ_1|ALLELE_FREQ_2|\n",
      "+---------+-------------+-------------+\n",
      "|rs4109479|  C:0.0434783|   T:0.956522|\n",
      "+---------+-------------+-------------+\n",
      "\n",
      "+---------+-----+-------------+-------------+\n",
      "|       ID|CHROM|ALLELE_FREQ_1|ALLELE_FREQ_2|\n",
      "+---------+-----+-------------+-------------+\n",
      "|rs4109479|   11|  C:0.0434783|   T:0.956522|\n",
      "+---------+-----+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freqDF_working.select(freqDF_working.ID, freqDF_working.ALLELE_FREQ_1, freqDF_working.ALLELE_FREQ_2).filter(freqDF_working.ID == \"rs4109479\").show()\n",
    "freqDF_working.select(\"ID\", \"CHROM\", \"ALLELE_FREQ_1\", \"ALLELE_FREQ_2\").filter(\"ID == 'rs4109479'\").show()\n",
    "#spark.sql(\"select ID, ALLELE_FREQ_1, ALLELE_FREQ_2 from freqDF_working where ID = 'rs4109479'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct rows: {0}'.format(freqDF_working.distinct().count()))\n",
    "# freqDF_working = freqDF_working.dropDuplicates()\n",
    "# print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct rows: {0}'.format(freqDF_working.distinct().count()))\n",
    "# print('Count of IDs: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct IDs: {0}'.format(freqDF_working.select(freqDF_working.ID).distinct().count()))\n",
    "# freqDF_working.where(\"ID = '.'\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
