{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenoSpark for Singapore population genotypic frequency\n",
    "\n",
    "## First, generate the output files with the command syntax below:\n",
    "```\n",
    "$ vcftools --gzvcf chr[#].consolidate.eff.PPH.vcf.gz --freq --chr [#] --out chr[#]_analysis\n",
    "$ bcftools query -f '%CHROM\\t%POS\\t%ID\\n' chr[#].consolidate.eff.PPH.vcf.gz -o chr[#]_rsID\n",
    "```\n",
    "\n",
    "#### * You may try freqGenerator.sh to generate the above files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "__author__ = 'mdc_hk'\n",
    "version = '1.0'\n",
    "\n",
    "# Description: To build the database on the pyspark DataFrame\n",
    "# Usage: -\n",
    "# Example: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime, multiprocessing, os, re, shutil, sys, subprocess, time, logging\n",
    "\n",
    "import pyspark.sql.types as typ\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "# Specify schemas\n",
    "\n",
    "schema_Freq = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_ALLELES\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_CHR\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_1\", typ.StringType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_2\", typ.StringType(), False),\n",
    "])\n",
    "\n",
    "schema_rsID = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ID\", typ.StringType(), True),\n",
    "])\n",
    "\n",
    "schema_Freq_DF = typ.StructType([\n",
    "    typ.StructField(\"CHROM\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"POS\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_ALLELES\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"N_CHR\", typ.IntegerType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_1\", typ.StringType(), False),\n",
    "    typ.StructField(\"ALLELE_FREQ_2\", typ.StringType(), False),\n",
    "    typ.StructField(\"ID\", typ.StringType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chr10'], ['chr11'], ['chr12'], ['chr13'], ['chr14'], ['chr15'], ['chr16'], ['chr17'], ['chr18'], ['chr19'], ['chr1'], ['chr20'], ['chr21'], ['chr22'], ['chr2'], ['chr3'], ['chr4'], ['chr5'], ['chr6'], ['chr7'], ['chr8'], ['chr9']]\n"
     ]
    }
   ],
   "source": [
    "# Setting up File Paths and Lists\n",
    "\n",
    "from hdfs import Config\n",
    "client = Config().get_client('dev')\n",
    "\n",
    "workingFolder_Indian = \"SgIndian_vcf/dataFreeze_Feb2013/SNP/biAllele/\"\n",
    "\n",
    "workingFolder_Malay = \"SgMalay_vcf/2012_05/snps/\"\n",
    "\n",
    "# Filing number of unique samples found in the working folder...\n",
    "\n",
    "freqFiles_Indian = [f for f in client.list(workingFolder_Indian) if re.match(r'chr\\d+_analysis\\.frq', f)]\n",
    "rsIDFiles_Indian = [f for f in client.list(workingFolder_Indian) if re.match(r'chr\\d+_rsID', f)]\n",
    "freqFiles_Malay = [f for f in client.list(workingFolder_Malay) if re.match(r'chr\\d+_analysis\\.frq', f)]\n",
    "rsIDFiles_Malay = [f for f in client.list(workingFolder_Malay) if re.match(r'chr\\d+_rsID', f)]\n",
    "\n",
    "freqFilesID_pre = re.compile(r'(chr\\d+)_analysis\\.frq')\n",
    "freqFilesID = []\n",
    "for file in freqFiles_Indian:\n",
    "    freqFilesID.append(freqFilesID_pre.findall(file))\n",
    "\n",
    "print(freqFilesID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain dataset\n",
    "\n",
    "# suffixFreqID = ['_analysis.frq', '_rsID']\n",
    "freqDF_Indian = spark.createDataFrame([], schema_Freq_DF)\n",
    "freqDF_Malay = spark.createDataFrame([], schema_Freq_DF)\n",
    "\n",
    "for ID in freqFilesID:\n",
    "    df1 = spark.read.csv(workingFolder_Indian + ID[0] + \"_analysis.frq\", header=True, schema=schema_Freq, sep='\\t').alias('df1')\n",
    "    df2 = spark.read.csv(workingFolder_Indian + ID[0] + \"_rsID\", header=False, schema=schema_rsID, sep='\\t').alias('df2')\n",
    "    freqChrN_working = df2.join(df1, df2.POS == df1.POS).select('df1.*','df2.ID')\n",
    "    freqDF_Indian = freqDF_Indian.union(freqChrN_working)\n",
    "    \n",
    "for ID in freqFilesID:\n",
    "    df1 = spark.read.csv(workingFolder_Malay + ID[0] + \"_analysis.frq\", header=True, schema=schema_Freq, sep='\\t').alias('df1')\n",
    "    df2 = spark.read.csv(workingFolder_Malay + ID[0] + \"_rsID\", header=False, schema=schema_rsID, sep='\\t').alias('df2')\n",
    "    freqChrN_working = df2.join(df1, df2.POS == df1.POS).select('df1.*','df2.ID')\n",
    "    freqDF_Malay = freqDF_Malay.union(freqChrN_working)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqDF_Indian_working = freqDF_Indian.withColumn(\"ETHNIC\", lit(\"Indian\"))\n",
    "freqDF_Malay_working = freqDF_Malay.withColumn(\"ETHNIC\", lit(\"Malay\"))\n",
    "freqDF_working = freqDF_Malay_working.union(freqDF_Indian_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDF_working.show(10)\n",
    "#freqDF_working.select(\"ETHNIC\", \"ID\", \"CHROM\", \"ALLELE_FREQ_1\", \"ALLELE_FREQ_2\").filter(\"ID == 'rs4109479'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"select * from freqDF_working\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "freqDF_working.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqDF_working.select(freqDF_working.ID, freqDF_working.ALLELE_FREQ_1, freqDF_working.ALLELE_FREQ_2).filter(freqDF_working.ID == \"rs4109479\").show()\n",
    "freqDF_working.select(\"ID\", \"CHROM\", \"ALLELE_FREQ_1\", \"ALLELE_FREQ_2\").filter(\"ID == 'rs4109479'\").show()\n",
    "spark.sql(\"select ID, ALLELE_FREQ_1, ALLELE_FREQ_2 from freqDF_working where ID = 'rs4109479'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct rows: {0}'.format(freqDF_working.distinct().count()))\n",
    "# freqDF_working = freqDF_working.dropDuplicates()\n",
    "# print('Count of rows: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct rows: {0}'.format(freqDF_working.distinct().count()))\n",
    "# print('Count of IDs: {0}'.format(freqDF_working.count()))\n",
    "# print('Count of distinct IDs: {0}'.format(freqDF_working.select(freqDF_working.ID).distinct().count()))\n",
    "# freqDF_working.where(\"ID = '.'\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
